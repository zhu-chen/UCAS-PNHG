# PENS基线方法综合配置文件

# 数据路径配置
paths:
  raw_data: "data/raw"
  processed_data: "data/processed"
  embeddings: "data/embeddings"
  results: "results/baseline"
  logs: "logs/baseline"

# 数据文件路径（训练器需要的格式）
data:
  train_path: "data/processed/train_processed.pkl"
  valid_path: "data/processed/valid_processed.pkl"
  test_path: "data/processed/test_processed.pkl"

# 数据预处理配置
preprocessing:
  # 数据采样配置（用于减少内存使用）
  data_sample_ratio: 0.01
  max_samples_per_split: 5000
  max_pos_samples_per_user: 2
  max_neg_samples_per_user: 1
  negative_sample_ratio: 0.005
  include_negative_samples: true
  
  # 文本长度限制
  max_title_length: 20   
  max_body_length: 500   
  max_user_history: 5    
  
  # 词汇表配置
  vocab_size: 15000      
  min_word_freq: 2      

# 模型配置
model:
  # NAML用户编码器配置
  user_encoder:
    embedding_dim: 300      
    hidden_dim: 400         
    max_history_length: 50  
    num_categories: 15      
    dropout: 0.2            
  
  # Transformer编码器配置
  transformer:
    embedding_dim: 300    
    d_model: 300          
    sentence_pos_dim: 100 
    dropout: 0.2          
    max_length: 500       
  
  # 指针网络解码器配置 - 修复参数名称
  decoder:
    embedding_dim: 300      # 词嵌入维度
    hidden_dim: 400         # 隐藏层维度（与Transformer输出匹配）
    num_layers: 2           # LSTM层数
    dropout: 0.2            # Dropout率
    max_decode_length: 30   # 最大解码长度
    decoder_type: 2         # F2策略
    user_size: 64           # NAML输出维度
  
  # 极简生成器配置
  generator:
    embedding_dim: 64
    hidden_dim: 128     
    num_layers: 1      
    dropout: 0.3
    max_decode_length: 15  
  
  # 词嵌入配置
  word_embedding:
    dim: 128            
    pretrained: false

# 训练配置
training:
  # 简化的训练策略
  mode: "simple"  
  epochs: 30          
  batch_size: 8      
  learning_rate: 0.0001  
  weight_decay: 0.00001  
  optimizer: "adam"
  
  # 设备配置
  device: "cuda"  
  num_workers: 0         
  pin_memory: false
  gradient_clip: 0.5    
  
  # 评估配置
  eval_every: 100
  save_every: 500
  early_stopping_patience: 3
  
  # 日志配置
  log_level: "INFO"
  save_model: true

# 训练器需要的配置项
num_epochs: 30          
batch_size: 8          
device: "cuda"         
num_workers: 0         
vocab_size: 15000      
min_word_freq: 2       
max_title_length: 20   
max_body_length: 100   
max_user_history: 2    
grad_clip: 0.5         
patience: 3
save_every: 5
teacher_forcing_ratio: 1.0

# 优化器配置
optimizer:
  lr: 0.0001             # 大幅降低学习率
  user_encoder_lr: 0.0001  # 用户编码器使用更小的学习率
  weight_decay: 0.00001     # 降低权重衰减
  eps: 0.0000001             # 改善数值稳定性

# 学习率调度器配置
scheduler:
  type: "linear"
  warmup_ratio: 0.1

# 检查点配置
checkpoint:
  dir: "results/baseline/checkpoints"
  max_keep: 3

# 评估配置
evaluation:
  metrics:
    - "rouge_1"
    - "rouge_2" 
    - "rouge_l"
    - "bleu"
  batch_size: 8